"First Author","Year","Title","Venue / Publisher","Link","Quote in paper"
"Raffel","2014","mir_eval: A Transparent Implementation of Common MIR Metrics","ISMIR","https://craffel.github.io/mir_eval/#module-mir_eval.transcription","Onsets must be within 50 ms and offsets within 20% of reference duration (or 50 ms, whichever is larger)."
"Hawthorne","2018","Onsets and Frames: Dual-Objective Piano Transcription","arXiv","https://ar5iv.org/html/1710.11153","As is standard, we calculate two versions of note metrics: onset within 50 ms; and onset+offset within 20% or 50 ms."
"Hawthorne","2019","MAESTRO: A Dataset for Model-Based Piano Transcription and Generation","arXiv","https://arxiv.org/abs/1810.12247","Over 200 hours of virtuosic piano performances captured with aligned MIDI and audio."
"Emiya","2010","Multipitch Estimation of Piano Sounds Using a New Piano Database (MAPS)","IEEE TASLP","https://doi.org/10.1109/TASL.2010.2048919","MAPS contains isolated notes, chords and complete pieces, including Disklavier recordings."
"Thickstun","2017","Learning Features of Music from Scratch","ICLR Workshop / arXiv","https://arxiv.org/abs/1611.09827","MusicNet is a collection of 330 classical recordings with time-aligned, instrument-labeled annotations."
"Manilow","2019","Slakh2100: A Dataset and Challenge for Learning from Labeled Slakh","ISMIR","https://arxiv.org/abs/1909.08400","High-quality multitrack audio renderings with aligned MIDI from the Lakh MIDI Dataset."
"Li","2018","URMP: University of Rochester Multimodal Music Performance Dataset","ISMIR","https://www2.ece.rochester.edu/projects/air/projects/URMP.html","Audio-visual recordings of classical chamber music with separate tracks and annotations."
"Xi","2018","GuitarSet: A Dataset for Guitar Transcription","ISMIR","https://zenodo.org/record/3371780","Real guitar performances with hexaphonic pickup; audio and frame-level annotations for all six strings."
"Lostanlen","2018","Medley-solos-DB: a Cross-Collection Dataset of Solo Musical Phrases","Zenodo / ISMIR ext.","https://doi.org/10.5281/zenodo.1344103","Solo phrases across instruments with standardized labels and metadata."
"Gillet","2006","ENST-Drums: An Extensive Audio-Visual Database for Drum Signals","ISMIR","https://doi.org/10.5281/zenodo.4272301","A large database of drum recordings designed for transcription and separation tasks."
"Foscarin","2020","ASAP: A Dataset for Expressive Piano Performance Analysis and Alignment","arXiv","https://arxiv.org/abs/2010.06088","Aligned scores and performances enabling evaluation of expressive timing and articulation."
"Kong","2020","GiantMIDI-Piano: Classically Trained, Large-Scale MIDI Dataset","arXiv","https://arxiv.org/abs/1912.05946","A large-scale dataset transcribed from YouTube classical piano recordings."
"Wang","2020","POP909: A Pop-Music Dataset for Music Arrangement","ISMIR","https://github.com/music-x-lab/POP909-Dataset","909 pop songs with aligned piano scores, structure annotations, and audio."
"Gardner","2023","MT3: Multi-Task, Multi-Track, Multi-Instrument Music Transcription","arXiv","https://arxiv.org/abs/2104.04699","Produces instrument-conditioned, multi-track MIDI with a unified model across tasks and instruments."
"Kong","2021","High-Resolution Piano Transcription with Pedals","arXiv","https://arxiv.org/abs/2107.07312","Models sustain and una corda pedals to improve note and duration accuracy in transcription."
"Raffel","2014","Intuitive Analysis, Creation and Manipulation of MIDI Data with pretty_midi","ISMIR (LBD)","https://colinraffel.com/publications/ismir2014intuitive.pdf","pretty_midi focuses on fast, straightforward analysis, modification, and generation of MIDI data."
"Cuthbert","2010","music21: A Toolkit for Computer-Aided Musicology and Symbolic Music Data","ISMIR","https://dspace.mit.edu/handle/1721.1/84963","music21 provides objects for notes, ornaments, and score structures for symbolic analysis."
"music21 Docs","2024","User’s Guide, Chapter 27: Grace Notes","music21 Docs","https://www.music21.org/music21docs/usersGuide/usersGuide_27_graceNotes.html","Grace notes present particular problems … in one view they take up no time whatsoever."
"mir_eval (melody)","2014","Melody Evaluation Metrics (Raw/Chroma Accuracy)","mir_eval Docs","https://craffel.github.io/mir_eval/#mir_eval.melody","Raw chroma accuracy counts octave errors as correct by mapping to pitch class."
"Engel","2017","Neural Audio Synthesis with WaveNet Autoencoders (NSynth)","ICML","https://proceedings.mlr.press/v70/engel17a/engel17a.pdf","NSynth … introduces a large-scale dataset of musical notes with instrument family labels."
"Gemmeke","2017","AudioSet: An Ontology and Human-Labeled Dataset for Audio Events","ICASSP","https://research.google/pubs/pub45857/","An ontology of 632 audio event classes and over 2 million labeled 10-second clips."
"Humphrey","2018","OpenMIC-2018: An Open Dataset for Multiple Instrument Recognition","ISMIR","https://openmic-2018.github.io/","Crowdsourced, multi-label instrument presence annotations for real-world music."
"Jette","2002","SLURM: Simple Linux Utility for Resource Management","SC’02","https://slurm.schedmd.com/slurm_design.pdf","An open-source, fault-tolerant, highly scalable workload manager for clusters."
"Kurtzer","2017","Singularity: Scientific Containers for Mobility of Compute","PLoS ONE","https://pmc.ncbi.nlm.nih.gov/articles/PMC5426675/","Singularity enables portable, reproducible execution of complete software environments."
"RCAC","2024","Gilbreth User Guide (SLURM Usage on Purdue RCAC)","Purdue RCAC","https://www.rcac.purdue.edu/knowledge/gilbreth/run","There is one method for submitting jobs to Gilbreth. You may use SLURM to submit jobs."
